{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1: How does an LLM-driven synthetic guideline affect diagnostic accuracy through clinical reasoning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Llama 3.3 (70B)</th>\n",
       "      <th>zeroshot</th>\n",
       "      <td>80.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>53.57</td>\n",
       "      <td>74.00</td>\n",
       "      <td>85.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot1</th>\n",
       "      <td>83.08</td>\n",
       "      <td>91.89</td>\n",
       "      <td>71.43</td>\n",
       "      <td>80.95</td>\n",
       "      <td>86.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot2</th>\n",
       "      <td>81.54</td>\n",
       "      <td>91.89</td>\n",
       "      <td>67.86</td>\n",
       "      <td>79.07</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>89.23</td>\n",
       "      <td>94.59</td>\n",
       "      <td>82.14</td>\n",
       "      <td>87.50</td>\n",
       "      <td>90.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Phi 4 (14B)</th>\n",
       "      <th>zeroshot</th>\n",
       "      <td>75.38</td>\n",
       "      <td>91.89</td>\n",
       "      <td>53.57</td>\n",
       "      <td>72.34</td>\n",
       "      <td>80.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot1</th>\n",
       "      <td>72.31</td>\n",
       "      <td>83.78</td>\n",
       "      <td>57.14</td>\n",
       "      <td>72.09</td>\n",
       "      <td>77.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot2</th>\n",
       "      <td>70.77</td>\n",
       "      <td>86.49</td>\n",
       "      <td>50.00</td>\n",
       "      <td>69.57</td>\n",
       "      <td>77.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>81.54</td>\n",
       "      <td>91.89</td>\n",
       "      <td>67.86</td>\n",
       "      <td>79.07</td>\n",
       "      <td>85.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Llama 3.1 (8B)</th>\n",
       "      <th>zeroshot</th>\n",
       "      <td>60.00</td>\n",
       "      <td>89.19</td>\n",
       "      <td>21.43</td>\n",
       "      <td>60.00</td>\n",
       "      <td>71.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot1</th>\n",
       "      <td>70.77</td>\n",
       "      <td>97.30</td>\n",
       "      <td>35.71</td>\n",
       "      <td>66.67</td>\n",
       "      <td>79.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot2</th>\n",
       "      <td>63.08</td>\n",
       "      <td>97.30</td>\n",
       "      <td>17.86</td>\n",
       "      <td>61.02</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>58.46</td>\n",
       "      <td>43.24</td>\n",
       "      <td>78.57</td>\n",
       "      <td>72.73</td>\n",
       "      <td>54.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">DeepSeek-R1 (70B)</th>\n",
       "      <th>zeroshot</th>\n",
       "      <td>73.85</td>\n",
       "      <td>100.00</td>\n",
       "      <td>19.05</td>\n",
       "      <td>72.13</td>\n",
       "      <td>83.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot1</th>\n",
       "      <td>75.38</td>\n",
       "      <td>97.30</td>\n",
       "      <td>46.43</td>\n",
       "      <td>70.59</td>\n",
       "      <td>81.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot2</th>\n",
       "      <td>69.23</td>\n",
       "      <td>94.59</td>\n",
       "      <td>35.71</td>\n",
       "      <td>66.04</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>60.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>7.14</td>\n",
       "      <td>58.73</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">DeepSeek-R1 (32B)</th>\n",
       "      <th>zeroshot</th>\n",
       "      <td>69.23</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4.76</td>\n",
       "      <td>68.75</td>\n",
       "      <td>81.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot1</th>\n",
       "      <td>78.46</td>\n",
       "      <td>91.89</td>\n",
       "      <td>60.71</td>\n",
       "      <td>75.56</td>\n",
       "      <td>82.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot2</th>\n",
       "      <td>81.54</td>\n",
       "      <td>97.30</td>\n",
       "      <td>60.71</td>\n",
       "      <td>76.60</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>56.92</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56.92</td>\n",
       "      <td>72.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">DeepSeek-R1 (14B)</th>\n",
       "      <th>zeroshot</th>\n",
       "      <td>80.00</td>\n",
       "      <td>90.91</td>\n",
       "      <td>57.14</td>\n",
       "      <td>81.63</td>\n",
       "      <td>86.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot1</th>\n",
       "      <td>78.46</td>\n",
       "      <td>83.78</td>\n",
       "      <td>71.43</td>\n",
       "      <td>79.49</td>\n",
       "      <td>81.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewshot2</th>\n",
       "      <td>72.31</td>\n",
       "      <td>81.08</td>\n",
       "      <td>60.71</td>\n",
       "      <td>73.17</td>\n",
       "      <td>76.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom</th>\n",
       "      <td>73.85</td>\n",
       "      <td>72.97</td>\n",
       "      <td>75.00</td>\n",
       "      <td>79.41</td>\n",
       "      <td>76.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy  sensitivity  specificity  precision  \\\n",
       "model             type                                                      \n",
       "Llama 3.3 (70B)   zeroshot     80.00       100.00        53.57      74.00   \n",
       "                  fewshot1     83.08        91.89        71.43      80.95   \n",
       "                  fewshot2     81.54        91.89        67.86      79.07   \n",
       "                  custom       89.23        94.59        82.14      87.50   \n",
       "Phi 4 (14B)       zeroshot     75.38        91.89        53.57      72.34   \n",
       "                  fewshot1     72.31        83.78        57.14      72.09   \n",
       "                  fewshot2     70.77        86.49        50.00      69.57   \n",
       "                  custom       81.54        91.89        67.86      79.07   \n",
       "Llama 3.1 (8B)    zeroshot     60.00        89.19        21.43      60.00   \n",
       "                  fewshot1     70.77        97.30        35.71      66.67   \n",
       "                  fewshot2     63.08        97.30        17.86      61.02   \n",
       "                  custom       58.46        43.24        78.57      72.73   \n",
       "DeepSeek-R1 (70B) zeroshot     73.85       100.00        19.05      72.13   \n",
       "                  fewshot1     75.38        97.30        46.43      70.59   \n",
       "                  fewshot2     69.23        94.59        35.71      66.04   \n",
       "                  custom       60.00       100.00         7.14      58.73   \n",
       "DeepSeek-R1 (32B) zeroshot     69.23       100.00         4.76      68.75   \n",
       "                  fewshot1     78.46        91.89        60.71      75.56   \n",
       "                  fewshot2     81.54        97.30        60.71      76.60   \n",
       "                  custom       56.92       100.00         0.00      56.92   \n",
       "DeepSeek-R1 (14B) zeroshot     80.00        90.91        57.14      81.63   \n",
       "                  fewshot1     78.46        83.78        71.43      79.49   \n",
       "                  fewshot2     72.31        81.08        60.71      73.17   \n",
       "                  custom       73.85        72.97        75.00      79.41   \n",
       "\n",
       "                            f1_score  \n",
       "model             type                \n",
       "Llama 3.3 (70B)   zeroshot     85.06  \n",
       "                  fewshot1     86.08  \n",
       "                  fewshot2     85.00  \n",
       "                  custom       90.91  \n",
       "Phi 4 (14B)       zeroshot     80.95  \n",
       "                  fewshot1     77.50  \n",
       "                  fewshot2     77.11  \n",
       "                  custom       85.00  \n",
       "Llama 3.1 (8B)    zeroshot     71.74  \n",
       "                  fewshot1     79.12  \n",
       "                  fewshot2     75.00  \n",
       "                  custom       54.24  \n",
       "DeepSeek-R1 (70B) zeroshot     83.81  \n",
       "                  fewshot1     81.82  \n",
       "                  fewshot2     77.78  \n",
       "                  custom       74.00  \n",
       "DeepSeek-R1 (32B) zeroshot     81.48  \n",
       "                  fewshot1     82.93  \n",
       "                  fewshot2     85.71  \n",
       "                  custom       72.55  \n",
       "DeepSeek-R1 (14B) zeroshot     86.02  \n",
       "                  fewshot1     81.58  \n",
       "                  fewshot2     76.92  \n",
       "                  custom       76.06  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Directory path containing JSONL files\n",
    "directory = \"results\"\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "data = []\n",
    "\n",
    "# Read only files ending with 'eval_results-clf.jsonl' within the directory\n",
    "for filename in filter(lambda f: f.endswith(\"eval_results-clf.jsonl\"), os.listdir(directory)):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    \n",
    "    # Extract model name (portion between 'snsb-' and '.eval_results.jsonl')\n",
    "    test_type, *model_name_parts = filename.split('.eval_results')[0].split('-')\n",
    "    model_name = \"-\".join(model_name_parts)\n",
    "    \n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse JSON data\n",
    "            json_data = json.loads(line.strip())\n",
    "            # Add extracted test type and model name to the data\n",
    "            json_data['type'] = test_type\n",
    "            json_data['model'] = model_name\n",
    "            data.append(json_data)\n",
    "\n",
    "# Convert the collected data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert accuracy, precision, sensitivity, specificity, and F1-score to percentages\n",
    "for metric in ['accuracy', 'sensitivity', 'specificity', 'precision', 'f1_score']:\n",
    "    df[metric] *= 100\n",
    "\n",
    "# Mapping of model names for better readability\n",
    "model_name_mapping = {\n",
    "    \"llama3.3:70b\": \"Llama 3.3 (70B)\",\n",
    "    \"phi4:14b\": \"Phi 4 (14B)\",\n",
    "    \"llama3.1:8b\": \"Llama 3.1 (8B)\",\n",
    "    \"deepseek-r1:70b\": \"DeepSeek-R1 (70B)\",\n",
    "    \"deepseek-r1:32b\": \"DeepSeek-R1 (32B)\",\n",
    "    \"deepseek-r1:14b\": \"DeepSeek-R1 (14B)\",\n",
    "}\n",
    "df['model'] = df['model'].replace(model_name_mapping)\n",
    "\n",
    "# Specify the desired order of model names and test types\n",
    "model_order = [\n",
    "    \"Llama 3.3 (70B)\", \"Phi 4 (14B)\", \"Llama 3.1 (8B)\",\n",
    "    \"DeepSeek-R1 (70B)\", \"DeepSeek-R1 (32B)\", \"DeepSeek-R1 (14B)\"\n",
    "]\n",
    "type_order = [\"zeroshot\", \"fewshot1\", \"fewshot2\", \"custom\"]\n",
    "\n",
    "# Sort the DataFrame by model and test type\n",
    "df['model'] = pd.Categorical(df['model'], categories=model_order, ordered=True)\n",
    "df['type'] = pd.Categorical(df['type'], categories=type_order, ordered=True)\n",
    "\n",
    "# Calculate average accuracy by model and test type\n",
    "df_clf = df.groupby(['model', 'type'], observed=True).mean()\n",
    "\n",
    "# Display relevant evaluation metrics\n",
    "df_clf[['accuracy', 'sensitivity', 'specificity', 'precision', 'f1_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2: How does an LLM-driven synthetic guideline impact on the quality of rationales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>custom</th>\n",
       "      <th>fewshot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>criteria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Llama 3.3 (70B)</th>\n",
       "      <th>consistency</th>\n",
       "      <td>83.08%</td>\n",
       "      <td>16.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness</th>\n",
       "      <td>80.00%</td>\n",
       "      <td>20.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>86.15%</td>\n",
       "      <td>13.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpfulness</th>\n",
       "      <td>81.54%</td>\n",
       "      <td>18.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humanlikeness</th>\n",
       "      <td>84.62%</td>\n",
       "      <td>15.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Phi 4 (14B)</th>\n",
       "      <th>consistency</th>\n",
       "      <td>66.15%</td>\n",
       "      <td>33.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctness</th>\n",
       "      <td>69.23%</td>\n",
       "      <td>30.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>76.92%</td>\n",
       "      <td>23.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpfulness</th>\n",
       "      <td>73.85%</td>\n",
       "      <td>26.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humanlikeness</th>\n",
       "      <td>73.85%</td>\n",
       "      <td>26.15%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "score                          custom fewshot\n",
       "model           criteria                     \n",
       "Llama 3.3 (70B) consistency    83.08%  16.92%\n",
       "                correctness    80.00%  20.00%\n",
       "                specificity    86.15%  13.85%\n",
       "                helpfulness    81.54%  18.46%\n",
       "                humanlikeness  84.62%  15.38%\n",
       "Phi 4 (14B)     consistency    66.15%  33.85%\n",
       "                correctness    69.23%  30.77%\n",
       "                specificity    76.92%  23.08%\n",
       "                helpfulness    73.85%  26.15%\n",
       "                humanlikeness  73.85%  26.15%"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Directory containing JSONL files\n",
    "directory = \"results/\"\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "collected_data = []\n",
    "\n",
    "# Iterate through files in the directory, processing only those ending with 'eval_results-rubric.jsonl'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\"eval_results-rubric.jsonl\"):  # Process only files matching the pattern\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Extract model name and data type from the filename\n",
    "        file_parts = filename.split('.eval_results')[0].split('-')\n",
    "        data_type = file_parts[0]  # Extract the data type (first part)\n",
    "        model_name = \"-\".join(file_parts[1:])  # Extract the model name (remaining parts)\n",
    "        \n",
    "        # Read and process the JSONL file\n",
    "        with open(filepath, 'r') as file:\n",
    "            for line in file:\n",
    "                json_data = json.loads(line.strip())  # Parse JSON data\n",
    "                json_data['data'] = data_type  # Add extracted data type\n",
    "                json_data['model'] = model_name  # Add extracted model name\n",
    "                collected_data.append(json_data)\n",
    "\n",
    "# Convert collected data into a DataFrame\n",
    "df = pd.DataFrame(collected_data)\n",
    "\n",
    "# Mapping of model names for better readability\n",
    "model_name_mapping = {\n",
    "    \"llama3.3:70b\": \"Llama 3.3 (70B)\",\n",
    "    \"phi4:14b\": \"Phi 4 (14B)\",\n",
    "}\n",
    "df['model'] = df['model'].replace(model_name_mapping)\n",
    "\n",
    "score_mapping = {\n",
    "    \"A\": \"custom\",\n",
    "    \"B\": \"fewshot\"\n",
    "}\n",
    "df['score'] = df['score'].replace(score_mapping)\n",
    "\n",
    "# Reorder the columns based on the specified order\n",
    "criterion_order = ['consistency', 'correctness', 'specificity', 'helpfulness', 'humanlikeness']\n",
    "\n",
    "# Sort the DataFrame by the specified order\n",
    "df['criteria'] = pd.Categorical(df['criteria'], categories=criterion_order, ordered=True)\n",
    "\n",
    "# Group data by 'model', and 'criteria', calculate normalized value counts of 'score'\n",
    "result = df.groupby(['model', 'criteria'], observed=True)['score'].value_counts(normalize=True).unstack()\n",
    "\n",
    "# Format the result as percentages\n",
    "formatted_result = result.map(lambda x: f'{x:.2%}')\n",
    "\n",
    "# Display the formatted DataFrame\n",
    "formatted_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mci-reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
